---
title: "Depression Data Analysis"
author: "Becca DeCamp"
date: "10/7/2017"
output: html_document
---
To start off, I loaded all of the data frames from the internet in to R (there are three separate data frames in total that I am pulling from). 
<br>Then, using the merge() function, I was able to concatenate those data frames in to one in two simple lines of code. 

```{r}

save(da36147.0003, file = "da36147.0003.RData")
load(file = "da36147.0003.RData")

save(da36147.0005, file = "da36147.0005.RData")
load(file = "da36147.0005.RData")

save(da36147.0008, file = "da36147.0008.RData")
load(file = "da36147.0008.RData")

newdata <- merge(da36147.0003, da36147.0005, by = c("HHX", "FPX"), all = TRUE)
head(newdata)

dep <- merge(newdata, da36147.0008, by = c("HHX", "FPX"), all = TRUE)
head(dep)
tail(dep)

```

As you can see, we got all the data in the place where we want it, but there's still way too much of it! Now we will filter the data and pull out only the columns we need from the 900-some columns that exist in the framework now. 

```{r}
library(dplyr)

```

